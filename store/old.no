
func (s *Store) Audit() error {
	// Copy the stores incase one is added later on
	var storesCopy = s.Stores[0:len(s.Stores)]

	// Iterate over all of the stores multiple times as changelogs are copied back and forth
	for i := 0; i < len(storesCopy)*len(storesCopy); i++ {
		// Assume the first store as the master for this iteration
		var (
			master     = storesCopy[0]
			waitLength time.Duration
		)

		// Range over all "slaves" of that master storage
		for _, slave := range storesCopy[1:] {
			// Iterate over all the changelogs
			var clIter, err = master.ChangelogIterator()
			if err != nil {
				return err
			}

			var (
				wg          sync.WaitGroup
				workerChan  = make(chan struct{}, 100)
				objectIDMap = map[string]*struct{}{}
			)

			// While we still have more changelogs ...
			// TODO: to speed this up we could define a time range, get all changelogs in that
			// time range and dispatch them
			for {
				// Get a changelog
				var cl, err = clIter.Next()
				if err != nil {
					if err == iterator.Done {
						waitLength = time.Duration((len(objectIDMap) / 1000)) * time.Second
						break
					}

					return err
				}

				// Check if we have already seen this objectID
				if objectIDMap[cl.ObjectID] != nil {
					continue
				}

				// Mark that we have seen this objectID
				objectIDMap[cl.ObjectID] = &struct{}{}

				wg.Add(1)
				workerChan <- struct{}{}
				go func() {
					defer func() {
						<-workerChan
						wg.Done()
					}()

					var err = processChangelogs(&wg, cl.ObjectID, master, slave)
					if err != nil {
						// log
					}
				}()
			}

			fmt.Println("i am here waiting")

			wg.Wait()
		}

		// Ring cycle through the stores
		storesCopy = append(storesCopy[1:len(storesCopy)], storesCopy[0])

		fmt.Println("Waiting ", waitLength, " to catch up")

		// Sleep for a bit to let the other store catch up with the load before we start again
		time.Sleep(waitLength)
	}

	return nil
}